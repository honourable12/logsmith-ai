# logsmith-ai

A high-performance Rust backend pipeline that ingests structured logs, processes them concurrently, and produces time-windowed features suitable for AI/ML training and monitoring.

This project is intentionally designed to demonstrate **backend engineering fundamentals**, **Rust concurrency**, and **AI systems awareness** at an entryâ€“junior level.

---

## ğŸš€ Why This Project Exists

Modern AI systems depend on reliable, high-throughput data ingestion pipelines. Raw logs must be:

* Parsed safely
* Processed concurrently
* Aggregated into fixed-size feature windows
* Exported in ML-friendly formats

`logsmith-ai` implements this end-to-end in **safe, idiomatic Rust**.

---

## âœ¨ Features

* ğŸ“¥ **Streaming ingestion** of large log files
* ğŸ§µ **Multi-threaded parsing** using message-passing (no shared mutable state)
* â±ï¸ **Time-windowed feature aggregation**
* ğŸ“¤ **CSV/Parquet export** for ML training pipelines
* âš¡ **Batch parallelism** using Rayon (offline workloads)
* ğŸ“Š **Benchmarks** using Criterion

---

## ğŸ—ï¸ Architecture Overview

```
file â†’ reader thread â†’ channel â†’ N worker threads â†’ channel â†’ windowed aggregator â†’ CSV
```

### Concurrency Model

* Ownership is transferred through channels
* No `Arc<Mutex<T>>`
* Channels provide backpressure and graceful shutdown

This mirrors real production ingestion pipelines.

---

## ğŸ“¦ Project Structure

```
logsmith-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest/        # File reading & parsing
â”‚   â”œâ”€â”€ pipeline/      # Channel & Rayon pipelines
â”‚   â”œâ”€â”€ features/      # Feature extraction & windowing
â”‚   â”œâ”€â”€ output/        # CSV export
â”‚   â””â”€â”€ main.rs
â”œâ”€â”€ benches/           # Criterion benchmarks
â””â”€â”€ tests/             # End-to-end tests
```

---

## ğŸ§ª Example Input

Each line is a JSON log event:

```json
{"timestamp":"2025-11-08T10:00:00Z","level":"INFO","latency_ms":120}
```

---

## ğŸ“Š Example Output (CSV)

```csv
window_start,window_end,request_count,avg_latency
2025-11-08T10:00:00Z,2025-11-08T10:05:00Z,842,124.6
```

This file can be loaded directly into Pandas, Spark, or ML training pipelines.

---

## âš¡ Streaming vs Batch Processing

| Use Case             | Approach           |
| -------------------- | ------------------ |
| Real-time ingestion  | Channels + threads |
| Offline dataset prep | Rayon              |

The project includes both implementations and benchmarks comparing them.

---

## ğŸ“Š Benchmarks

Benchmarks are implemented using **Criterion**:

```bash
cargo bench
```

They compare:

* Channel-based streaming parsing
* Rayon-based batch parsing

---

## ğŸ§  What This Demonstrates

* Rust ownership & lifetimes by design
* Safe concurrency without locks
* Backend data pipeline architecture
* AI/ML feature engineering awareness
* Performance measurement, not guesswork

---

## ğŸ› ï¸ Tech Stack

* Rust
* clap
* serde / serde_json
* chrono
* csv
* rayon
* criterion
* crossbeam-channel
* log
* env_logger
* arrow


---

## ğŸ“Œ Future Improvements

* Parquet export
* Prometheus metrics
* Async I/O
* Sliding windows

